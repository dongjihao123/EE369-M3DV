{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "reading test_data: 100%|██████████| 584/584 [00:09<00:00, 62.48it/s] \n",
      "croping: 100%|██████████| 116/116 [00:00<00:00, 221.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ada\\envs\\myvenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "from itertools import repeat\n",
    "\n",
    "def crop(array, zyx, dhw):\n",
    "    z, y, x = zyx\n",
    "    d, h, w = dhw\n",
    "    cropped = array[z - d // 2:z + d // 2,\n",
    "              y - h // 2:y + h // 2,\n",
    "              x - w // 2:x + w // 2]\n",
    "    return cropped\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,csv\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint,Callback\n",
    "\n",
    "for root, dirs,files in os.walk('test'):   \n",
    "    filename = files\n",
    "\n",
    "def sort_key(s):\n",
    "    return int(s[9:-4])\n",
    "\n",
    "test_number = sorted(filename,key = sort_key)         #获得排序的测试集\n",
    "\n",
    "#读取测试数据\n",
    "voxel_test = []     #用于存储测试数据的voxel\n",
    "seg_test = []       #用于存储测试数据的seg\n",
    "\n",
    "for i in tqdm(range(584), desc='reading test_data'):    #写入测试数据的进度\n",
    "    try:\n",
    "        tmp = np.load('test/candidate{}.npz'.format(i)) #依次读取测试数据中的candidate{i}文件\n",
    "    except FileNotFoundError:                           #无该文件时直接进入下一次循环\n",
    "        continue\n",
    "    try:\n",
    "        voxel_test = np.append(voxel_test, np.expand_dims(tmp['voxel'], axis=0), axis=0)    #向voxel_test中添加读取的voxel向量\n",
    "        seg_test = np.append(seg_test, np.expand_dims(tmp['seg'], axis=0), axis=0)          #向seg_test中添加读取的seg向量\n",
    "    except ValueError:\n",
    "        voxel_test = np.expand_dims(tmp['voxel'], axis=0)   #写入初次读取的voxel\n",
    "        seg_test = np.expand_dims(tmp['seg'], axis=0)       #写入初次读取的seg\n",
    "\n",
    "seg_test = seg_test.astype(np.int)      #将seg布尔array转换为1/0整数\n",
    "X_test= voxel_test*seg_test             #抠取结节\n",
    "\n",
    "X_test=X_test.astype(np.float32)\n",
    "X_test/=128.-1.\n",
    "\n",
    "test_batch_size = X_test.shape[0]  #测试数据集的数量\n",
    "\n",
    "X_test_new=crop(X_test[0],(50,50,50),(32,32,32))\n",
    "\n",
    "X_test_new=np.expand_dims(X_test_new,axis=0)\n",
    "\n",
    "for i in tqdm(range(test_batch_size-1),desc='croping'):\n",
    "    X_test_new=np.append(X_test_new,np.expand_dims(crop(X_test[i+1],(50,50,50),(32,32,32)),axis=0),axis=0)   \n",
    "del X_test\n",
    "X_test_new = X_test_new.reshape(X_test_new.shape[0], 32, 32, 32, 1)     #将测试数据集整合成5d张量\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "#载入模型 \n",
    "model = load_model('model.h5')\n",
    "\n",
    "#预测并存储结果\n",
    " \n",
    "y_pred=model.predict(X_test_new)\n",
    "\n",
    "test_label = []\n",
    "test_label.append(['id','Predicted'])\n",
    "for i in range(test_batch_size):\n",
    "    test_label.append([test_number[i][:-4],y_pred[i][1]])\n",
    "    \n",
    "with open('Submission.csv', 'w',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
